{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "246e71a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf230da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"https://www.amazon.{country}/dp/{asin}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ee00d8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product Title = \n",
      "Product Price = \n",
      "Product Rating = \n",
      "Number of Product Reviews = \n",
      "Availability = \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    " \n",
    "# Function to extract Product Title\n",
    "def get_title(soup):\n",
    "     \n",
    "    try:\n",
    "        # Outer Tag Object\n",
    "        title = soup.find(\"span\", attrs={\"id\":'productTitle'})\n",
    " \n",
    "        # Inner NavigableString Object\n",
    "        title_value = title.string\n",
    " \n",
    "        # Title as a string value\n",
    "        title_string = title_value.strip()\n",
    " \n",
    "        # # Printing types of values for efficient understanding\n",
    "        print(type(title))\n",
    "        print(type(title_value))\n",
    "        print(type(title_string))\n",
    "        print()\n",
    " \n",
    "    except AttributeError:\n",
    "        title_string = \"\"   \n",
    " \n",
    "    return title_string\n",
    " \n",
    "# Function to extract Product Price\n",
    "def get_price(soup):\n",
    " \n",
    "    try:\n",
    "        price = soup.find(\"span\", attrs={'id':'priceblock_ourprice'}).string.strip()\n",
    " \n",
    "    except AttributeError:\n",
    "        price = \"\"  \n",
    " \n",
    "    return price\n",
    " \n",
    "# Function to extract Product Rating\n",
    "def get_rating(soup):\n",
    " \n",
    "    try:\n",
    "        rating = soup.find(\"i\", attrs={'class':'a-icon a-icon-star a-star-4-5'}).string.strip()\n",
    "         \n",
    "    except AttributeError:\n",
    "         \n",
    "        try:\n",
    "            rating = soup.find(\"span\", attrs={'class':'a-icon-alt'}).string.strip()\n",
    "        except:\n",
    "            rating = \"\" \n",
    " \n",
    "    return rating\n",
    " \n",
    "# Function to extract Number of User Reviews\n",
    "def get_review_count(soup):\n",
    "    try:\n",
    "        review_count = soup.find(\"span\", attrs={'id':'acrCustomerReviewText'}).string.strip()\n",
    "         \n",
    "    except AttributeError:\n",
    "        review_count = \"\"   \n",
    " \n",
    "    return review_count\n",
    " \n",
    "# Function to extract Availability Status\n",
    "def get_availability(soup):\n",
    "    try:\n",
    "        available = soup.find(\"div\", attrs={'id':'availability'})\n",
    "        available = available.find(\"span\").string.strip()\n",
    " \n",
    "    except AttributeError:\n",
    "        available = \"\"  \n",
    " \n",
    "    return available    \n",
    " \n",
    "if __name__ == '__main__':\n",
    " \n",
    "    # Headers for request\n",
    "    HEADERS = ({'User-Agent':\n",
    "                'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/44.0.2403.157 Safari/537.36',\n",
    "                'Accept-Language': 'en-US, en;q=0.5'})\n",
    " \n",
    "    # The webpage URL\n",
    "    URL = \"https://www.amazon.com/Sony-PlayStation-Pro-1TB-Console-4/dp/B07K14XKZH/\"\n",
    " \n",
    "    # HTTP Request\n",
    "    webpage = requests.get(URL, headers=HEADERS)\n",
    " \n",
    "    # Soup Object containing all data\n",
    "    soup = BeautifulSoup(webpage.content, \"lxml\")\n",
    " \n",
    "    # Function calls to display all necessary product information\n",
    "    print(\"Product Title =\", get_title(soup))\n",
    "    print(\"Product Price =\", get_price(soup))\n",
    "    print(\"Product Rating =\", get_rating(soup))\n",
    "    print(\"Number of Product Reviews =\", get_review_count(soup))\n",
    "    print(\"Availability =\", get_availability(soup))\n",
    "    print()\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "02b34293",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fetch links as List of Tag Objects\n",
    "links = soup.find_all(\"a\", attrs={'class':'a-link-normal s-no-outline'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "68bbae3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Store the links\n",
    "links_list = []\n",
    " \n",
    "# Loop for extracting links from Tag Objects\n",
    "for link in links:\n",
    "    links_list.append(link.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "298b9959",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (Temp/ipykernel_19280/893346887.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\ASUS\\AppData\\Local\\Temp/ipykernel_19280/893346887.py\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    for link in links_list:\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# Loop for extracting product details from each link \n",
    "    for link in links_list:\n",
    "         \n",
    "        new_webpage = requests.get(\"https://www.amazon.com\" + link, headers=HEADERS)\n",
    "        new_soup = BeautifulSoup(new_webpage.content, \"lxml\")\n",
    "         \n",
    "        print(\"Product Title =\", get_title(new_soup))\n",
    "        print(\"Product Price =\", get_price(new_soup))\n",
    "        print(\"Product Rating =\", get_rating(new_soup))\n",
    "        print(\"Number of Product Reviews =\", get_review_count(new_soup))\n",
    "        print(\"Availability =\", get_availability(new_soup))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8ce3e9bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'strip'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9664/3034373022.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[0mprice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprice\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m \u001b[0mtitle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'strip'"
     ]
    }
   ],
   "source": [
    "# import libraries \n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import smtplib\n",
    "# Connect to Website and pull in data\n",
    "\n",
    "URL = 'https://www.amazon.com/Funny-Data-Systems-Business-Analyst/dp/B07FNW9FGJ/ref=sr_1_3?dchild=1&keywords=data%2Banalyst%2Btshirt&qid=1626655184&sr=8-3&customId=B0752XJYNL&th=1'\n",
    "\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.108 Safari/537.36\", \"Accept-Encoding\":\"gzip, deflate\", \"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\", \"DNT\":\"1\",\"Connection\":\"close\", \"Upgrade-Insecure-Requests\":\"1\"}\n",
    "\n",
    "page = requests.get(URL, headers=headers)\n",
    "\n",
    "soup1 = BeautifulSoup(page.content, \"html.parser\")\n",
    "soup2 = BeautifulSoup(soup1.prettify(), \"html.parser\")\n",
    "try:\n",
    "    # Outer Tag Object\n",
    "    title = soup.find(\"span\", attrs={\"id\":'productTitle'})\n",
    "\n",
    "    # Inner NavigableString Object\n",
    "    title_value = title.string\n",
    "\n",
    "    # Title as a string value\n",
    "    title_string = title_value.strip()\n",
    "\n",
    "    # # Printing types of values for efficient understanding\n",
    "    print(type(title))\n",
    "    print(type(title_value))\n",
    "    print(type(title_string))\n",
    "    print()\n",
    "\n",
    "except AttributeError:\n",
    "    title_string = \"\"   \n",
    "\n",
    "\n",
    "try:\n",
    "    price = soup.find(\"span\", attrs={'id':'priceblock_ourprice'}).string.strip()\n",
    "\n",
    "except AttributeError:\n",
    "\n",
    "    try:\n",
    "        # If there is some deal price\n",
    "        price = soup.find(\"span\", attrs={'id':'priceblock_dealprice'}).string.strip()\n",
    "\n",
    "    except:     \n",
    "        price = \"\"  \n",
    "# print(title)\n",
    "# print(price)\n",
    "# Clean up the data a little bit\n",
    "\n",
    "price = price.strip()[1:]\n",
    "title = title.strip()\n",
    "\n",
    "print(title)\n",
    "# print(price)\n",
    "# Create a Timestamp for your output to track when data was collected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cdce87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e784e7a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6facd770",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773bee8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba7e4b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1086f925",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fe33ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2a0414",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2693e6d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
